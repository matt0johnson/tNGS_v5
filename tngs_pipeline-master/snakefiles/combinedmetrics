import csv

samples = config["samples"]
batch_id = config["batch_id"]
workbatch = config["workbatch"]

phenotypes =[]
for sample in samples:
    phenotypes.append(config["samples"][sample][4])
phenotypes = list(set(phenotypes))

def generate_filename(folder, suffix):
    if suffix == "phenotype_bait_capture_metrics":  
        for sample in config["samples"]:
            gender = config["samples"][sample][2]
            panel = config["samples"][sample][4]
            filename = "%s/%s/%s-%s-%s_%s" % (workbatch,folder,sample,gender,panel,suffix)
            yield filename
    elif suffix == "overall_bait_capture_metrics":
        for sample in config["samples"]:
            gender = config["samples"][sample][2]
            filename = "%s/%s/%s-%s_%s" % (workbatch,folder,sample,gender,suffix)
            yield filename
    else:
        for sample in config["samples"]:
            filename = "%s/%s/%s.%s" % (workbatch,folder,sample,suffix)
            yield filename

rule combine_metrics:
    input:
        expand(generate_filename("metrics/hsmetrics", "overall_bait_capture_metrics")),
    output:
        "{workbatch}/metrics/{batch_id}_overall_metrics"
    run:
       lines = [] 
       
       for file in input:         
           with open(file) as infile:
               csvreader = csv.reader(infile, delimiter = '\t')
               for row in csvreader:
                   if len(row) > 0:
                       for sample in samples:
                           if sample in row:
                               lines.append(row)
       
       with open(output[0], "w") as outfile:
           csvwriter = csv.writer(outfile, delimiter = '\t')
           csvwriter.writerow(["bait_set","genome_size","bait_territory","target_territory","bait_design_efficiency","total_reads","pf_reads","pf_unique_reads","pct_pf_reads","pct_pf_uq_reads","pf_uq_reads_aligned","pct_pf_uq_reads_aligned","pf_bases_aligned","pf_uq_bases_aligned","on_bait_bases","near_bait_bases","off_bait_bases","on_target_bases","pct_selected_bases","pct_off_bait","on_bait_vs_selected","mean_bait_coverage","mean_target_coverage","median_target_coverage","pct_usable_bases_on_bait","pct_usable_bases_on_target","fold_enrichment","zero_cvg_targets_pct","pct_exc_dupe","pct_exc_mapq","pct_exc_baseq","pct_exc_overlap","pct_exc_off_target","fold_80_base_penalty","pct_target_bases_1x","pct_target_bases_2x","pct_target_bases_10x","pct_target_bases_20x","pct_target_bases_30x","pct_target_bases_40x","pct_target_bases_50x","pct_target_bases_100x","hs_library_size","hs_penalty_10x","hs_penalty_20x","hs_penalty_30x","hs_penalty_40x","hs_penalty_50x","hs_penalty_100x","at_dropout","gc_dropout","het_snp_sensitivity","het_snp_q","sample_id","library","read_group"])
           for line in lines:
               csvwriter.writerow(line)    

rule combine_phenotype_metrics:    
    input:
        expand(generate_filename("metrics/hsmetrics", "phenotype_bait_capture_metrics"))   
    output:
        expand("{workbatch}/metrics/{batch_id}_{phenotypes}_phenotype_metrics",workbatch=workbatch, batch_id=batch_id, phenotypes=phenotypes) 
    run:
        for phenotype in phenotypes:
            panel = []
            for sample in config["samples"]:
                if config["samples"][sample][4] == phenotype:
                    panel.append(sample)
            
            lines = []
            
            for sample in config["samples"]:    
                if sample in panel:
                    filename = workbatch + "/metrics/hsmetrics/" + sample + "-" + config["samples"][sample][2] + "-" + config["samples"][sample][4] + "_phenotype_bait_capture_metrics"
                    with open(filename) as infile:
                        csvreader = csv.reader(infile, delimiter = '\t')
                        for row in csvreader:
                            if len(row) > 0:
                                if sample in row:
                                    lines.append(row)
                         
            file = workbatch + "/metrics/" + batch_id + "_" + phenotype + "_phenotype_metrics"
                
            with open(file, "w") as outfile:
                csvwriter = csv.writer(outfile, delimiter = '\t')
                csvwriter.writerow(["bait_set","genome_size","bait_territory","target_territory","bait_design_efficiency","total_reads","pf_reads","pf_unique_reads","pct_pf_reads","pct_pf_uq_reads","pf_uq_reads_aligned","pct_pf_uq_reads_aligned","pf_bases_aligned","pf_uq_bases_aligned","on_bait_bases","near_bait_bases","off_bait_bases","on_target_bases","pct_selected_bases","pct_off_bait","on_bait_vs_selected","mean_bait_coverage","mean_target_coverage","median_target_coverage","pct_usable_bases_on_bait","pct_usable_bases_on_target","fold_enrichment","zero_cvg_targets_pct","pct_exc_dupe","pct_exc_mapq","pct_exc_baseq","pct_exc_overlap","pct_exc_off_target","fold_80_base_penalty","pct_target_bases_1x","pct_target_bases_2x","pct_target_bases_10x","pct_target_bases_20x","pct_target_bases_30x","pct_target_bases_40x","pct_target_bases_50x","pct_target_bases_100x","hs_library_size","hs_penalty_10x","hs_penalty_20x","hs_penalty_30x","hs_penalty_40x","hs_penalty_50x","hs_penalty_100x","at_dropout","gc_dropout","het_snp_sensitivity","het_snp_q","sample_id","library","read_group"])
                for line in lines:
                    csvwriter.writerow(line) 
                                
rule combine_duplicates:
    input:
        expand(generate_filename("metrics/duplicates", "dupmetrics"))            
    output:
        "{workbatch}/metrics/duplicates/{batch_id}_overall_duplicates"
    run:
        lines = []

        for file in input:
            with open(file) as infile:
                csvreader = csv.reader(infile, delimiter = '\t')
                for row in csvreader:
                    if len(row) > 0:
                        if batch_id in row:
                            filename = os.path.basename(file).split(".")[0]
                            row.append(filename)
                            lines.append(row)

        with open(output[0], "w") as outfile:
            csvwriter = csv.writer(outfile, delimiter = '\t')
            csvwriter.writerow(["LIBRARY","UNPAIRED_READS_EXAMINED","READ_PAIRS_EXAMINED","SECONDARY_OR_SUPPLEMENTARY_RDS","UNMAPPED_READS","UNPAIRED_READ_DUPLICATES","READ_PAIR_DUPLICATES","READ_PAIR_OPTICAL_DUPLICATES","PERCENT_DUPLICATION","ESTIMATED_LIBRARY_SIZE","SAMPLE"])
            for line in lines:
                csvwriter.writerow(line) 
            
